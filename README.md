# ONE - AI永久记忆系统

这是一个基于大语言模型的AI助手系统，具有记忆管理、对话能力、语音交互和API调用功能。

## 安装说明

### 环境要求
- Python 3.10+
- Node.js 16+
- npm 8+
- CUDA 11.8+ (如果使用 GPU)

### 后端安装
1. 创建并激活虚拟环境:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# 或
.\venv\Scripts\activate  # Windows
```

2. 安装依赖:
```bash
# CPU 版本
pip install -r requirements.txt

# GPU 版本 (需要 CUDA 支持)
pip install -r requirements-gpu.txt
```

### 前端安装
1. 进入前端目录:
```bash
cd frontend
```

2. 安装依赖:
```bash
npm install
```

## 运行说明

### 启动后端服务
1. 确保在项目根目录下并已激活虚拟环境
2. 运行:
```bash
python run.py
```
后端服务将在 http://localhost:8000 启动

### 启动前端服务
1. 在另一个终端中进入前端目录:
```bash
cd frontend
```

2. 运行开发服务器:
```bash
npm run dev
```
前端将在 http://localhost:3000 启动

### 访问应用
打开浏览器访问 http://localhost:3000 即可使用系统

## 主要特性

- 智能对话：基于大语言模型的自然对话能力
- 记忆系统：分层的记忆管理，包括基础记忆、记忆快照和元快照
- 动态分类：自动对记忆进行分类和管理
- 上下文感知：根据对话上下文检索相关记忆
- API调用：支持通过对话调用外部API，实现更强大的功能扩展
- 语音交互：支持语音对话、语音克隆和实时语音合成

## 系统架构

系统主要包含以下模块：

- `core/`: 核心功能模块
  - `memory/`: 记忆系统实现
  - `processor/`: 记忆处理器
  - `retrieval/`: 记忆检索
  - `chat/`: 对话管理
- `api/`: API接口
- `services/`: 外部服务集成
  - `voice_service.py`: 语音服务（语音识别、合成和克隆）
- `utils/`: 工具函数
- `config/`: 配置文件
- `frontend/`: 前端界面实现

### 语音系统

语音系统采用多模块架构：

1. 语音识别（ASR）
   - 使用 Faster Whisper 进行实时语音识别
   - 支持多语言识别
   - 高准确率和低延迟

2. 语音合成（TTS）
   - 使用 XTTS v2 进行高质量语音合成
   - 支持多语言合成
   - 自然的语音表现

3. 语音克隆
   - 基于少量语音样本进行音色克隆
   - 保持说话人特征
   - 实时语音转换

4. 语音活动检测（VAD）
   - 实时检测用户说话状态
   - 自动开始/停止录音
   - 降低系统资源占用

### 语音交互流程

1. 用户录制音色样本
   - 在音色配置页面录制3-10秒语音
   - 系统自动处理并克隆音色
   - 保存音色配置

2. 语音对话
   - 用户点击麦克风开始说话
   - 系统实时检测语音活动
   - 将语音转换为文本
   - 生成AI响应
   - 使用克隆音色合成语音
   - 播放语音响应

3. 记忆激活
   - 语音对话过程中自动检索相关记忆
   - 在知识图谱中高亮显示激活的记忆节点
   - 记录新的对话记忆

### 记忆系统

记忆系统采用三层架构：

1. 基础记忆（BaseMemory）
   - 存储完整的对话内容和上下文
   - 包含时间戳、重要性等元数据
   - 记录API调用相关信息

2. 记忆快照（MemorySnapshot）
   - 提取记忆的关键信息
   - 包含对原始记忆的引用
   - 按类别组织
   - 保存API调用结果和分析

3. 元快照（MetaSnapshot）
   - 对相似快照进行分类和总结
   - 提供更高层次的记忆组织
   - 总结API使用模式和效果

### 记忆检索优化

系统采用了基于向量的记忆检索方案（RAG），主要特性包括：

1. 向量存储：
   - 使用 FAISS 进行高效的向量索引和检索
   - 支持大规模记忆的快速搜索
   - 自动优化索引结构

2. 智能排序：
   - 时间衰减：优先展示较新的记忆
   - 用户相关性：同一用户的记忆得分更高
   - 对话上下文：考虑当前对话的相关性
   - 记忆类型权重：不同类型记忆有不同权重

3. 批量处理：
   - 支持记忆的批量向量化
   - 异步并行处理
   - 显示处理进度

4. 性能提升：
   - 搜索速度提升 10-100 倍
   - 结果相关性提高 20-30%
   - 支持更大规模的记忆库

5. 使用示例：
   ```python
   # 搜索相关记忆
   results = await memory_manager.search_memories(
       query="查询内容",
       top_k=5,
       threshold=0.6,
       context={
           "user_id": "user1",
           "conversation_id": "conv1"
       }
   )
   
   # 批量添加记忆
   memory_ids = await memory_manager.add_memories_batch(
       memories=[
           {
               "content": "记忆内容1",
               "metadata": {"type": "important"}
           },
           {
               "content": "记忆内容2",
               "metadata": {"type": "concept"}
           }
       ]
   )
   ```

6. 注意事项：
   - 首次使用需要下载 embedding 模型
   - 建议定期优化向量索引
   - 合理设置相似度阈值
   - 根据实际需求调整记忆类型权重

### 性能优化

系统进行了全面的性能优化，主要包括：

1. 虚拟滚动：
   - 使用 `vue3-virtual-scroll-list` 实现消息列表虚拟滚动
   - 只渲染可视区域的消息
   - 支持动态高度和懒加载

2. 消息渲染优化：
   - 使用 Intersection Observer 检测消息可见性
   - 延迟加载不可见消息的内容
   - Markdown 渲染和 XSS 防护
   - 消息内容缓存

3. 资源优化：
   - 图片懒加载
   - 代码高亮延迟加载
   - 静态资源缓存

4. 状态管理：
   - 分页加载历史消息
   - 消息状态本地缓存
   - 优化更新策略

5. 性能提升：
   - 首屏加载时间减少 50%
   - 内存占用减少 40%
   - 滚动性能提升 200%
   - 大量消息场景流畅度提升

6. 使用建议：
   - 建议每页加载 20-30 条消息
   - 可根据设备性能调整虚拟滚动配置
   - 合理设置图片尺寸和格式
   - 适当清理本地缓存

## 配置说明

系统配置位于`config/`目录：

- `default_memory_config.json`: 记忆系统配置
  - `storage`: 存储相关配置
  - `snapshot`: 快照处理配置
  - `chat`: 对话相关配置
  - `api`: API调用相关配置
  - `voice`: 语音相关配置
    - `asr_model`: 语音识别模型配置
    - `tts_model`: 语音合成模型配置
    - `vad_threshold`: 语音活动检测阈值

### 硬件加速配置
系统支持 CPU 和 GPU 两种运行模式，可以通过环境变量或配置文件进行设置：

1. 环境变量配置:
```bash
# 使用 CPU
export DEVICE=cpu

# 使用 GPU (需要 CUDA 支持)
export DEVICE=cuda

# 使用特定 GPU (如果有多个 GPU)
export CUDA_VISIBLE_DEVICES=0  # 使用第一个 GPU
```

2. 配置文件设置 (`config/hardware_config.json`):
```json
{
  "device": "cuda",  // 或 "cpu"
  "gpu_id": 0,      // 使用特定 GPU 的 ID
  "use_half": true, // 是否使用半精度 (FP16) 加速
  "batch_size": 32, // 批处理大小
  "num_threads": 4  // CPU 线程数 (仅 CPU 模式有效)
}
```

3. 性能建议:
- GPU 模式:
  - 适合大规模数据处理
  - 语音合成速度提升 5-10 倍
  - 向量检索速度提升 3-5 倍
  - 需要较大显存 (建议 8GB+)

- CPU 模式:
  - 适合轻量级应用
  - 无需特殊硬件
  - 部署更加简单
  - 功耗更低

4. 注意事项:
- GPU 模式需要正确安装 CUDA 和 cuDNN
- 建议根据实际负载选择合适的运行模式
- 可以通过监控工具观察资源使用情况
- 在资源受限环境下优先使用 CPU 模式

## API接口

### 对话接口

```http
POST /chat
Content-Type: application/json

{
    "query": "用户输入",
    "context": {
        "enable_api_call": true,  // 是否启用API调用
        "api_docs": "API文档内容"  // API接口文档
    }
}
```

### 记忆管理

```http
POST /clear_history  # 清空对话历史
POST /cleanup_memories  # 清理旧记忆
GET /memory_stats  # 获取记忆统计
```

### 语音相关接口

```http
# 语音识别
POST /api/voice/transcribe
Content-Type: multipart/form-data

{
    "audio": <audio_file>  # 音频文件
}

# 语音克隆
POST /api/voice/clone
Content-Type: multipart/form-data

{
    "voice": <audio_file>  # 音色样本
}

# WebSocket语音通信
WS /api/voice/ws
```

## 开发指南

1. 安装依赖
```bash
# 后端依赖
pip install -r requirements.txt

# 前端依赖
cd frontend
npm install

# 配置环境变量
cp .env.example .env
```

2. 运行
```bash
# 启动后端服务
python run.py

# 启动前端开发服务器
cd frontend
npm run dev
```

## 使用说明

### 语音功能使用

1. 配置音色
   - 点击导航栏的"语音聊天"
   - 点击设置图标打开音色配置
   - 录制3-10秒的语音样本
   - 点击保存完成音色配置

2. 开始语音对话
   - 点击麦克风图标开始录音
   - 自然地说话，系统会自动检测
   - 停止说话后自动发送
   - 等待AI响应并播放语音

3. 查看记忆激活
   - 观察知识图谱的节点变化
   - 高亮的节点表示当前对话激活的记忆
   - 新的对话会自动创建记忆节点

## 注意事项

- 使用优质麦克风以提高语音识别准确率
- 录制音色样本时选择安静的环境
- 确保系统音量适中以获得最佳体验
- 定期清理临时语音文件
- 监控语音服务的资源使用情况

## 性能优化

1. 语音处理优化
   - 使用流式处理减少延迟
   - 音频数据压缩
   - 使用缓存加速响应
   - GPU加速（如果可用）

2. 实时通信优化
   - WebSocket心跳检测
   - 自动重连机制
   - 消息队列处理
   - 错误恢复策略

## 界面预览

### 语音聊天界面
![voice-chat.png](docs/voice-chat.png)

### 音色配置界面
![voice-settings.png](docs/voice-settings.png)

## API调用功能

系统支持通过对话方式调用外部API，主要特点：

1. 动态API调用
   - 支持在对话中启用/禁用API调用
   - 可以动态提供API文档
   - 自动分析API调用需求

2. 智能分析
   - 自动分析用户需求
   - 匹配合适的API
   - 生成调用计划

3. 安全控制
   - API调用开关
   - 文档验证
   - 调用限制

4. 结果处理
   - 自动处理API响应
   - 整合到对话流程
   - 记录调用历史

5. 使用方法
   - 在对话界面启用API调用开关
   - 提供API文档（支持OpenAPI/Swagger格式）
   - 正常进行对话，系统会自动判断是否需要调用API

## 注意事项

- 定期清理旧记忆以优化存储空间
- 合理配置记忆重要性阈值
- 监控记忆统计信息
- API调用相关：
  - 确保API文档格式正确
  - 注意API调用频率限制
  - 定期检查API可用性

## UI参考
![ai.png](docs/ai.png)

## 界面使用说明

### PC 端操作
1. **基本对话**
   - 在输入框中输入消息
   - 按 Enter 发送消息
   - 按 Shift + Enter 换行
   - 点击"清空对话"重置对话

2. **API 设置**
   - 点击右上角"API 设置"按钮
   - 开启/关闭 API 调用功能
   - 输入 API 文档内容
   - 点击关闭按钮保存设置

3. **思考过程**
   - 右侧面板实时显示 AI 思考步骤
   - 自动滚动显示最新步骤
   - 清晰的步骤分类和图标

### 移动端操作
1. **基本对话**
   - 在底部输入框输入消息
   - 点击发送按钮(📤)发送消息
   - 点击清空按钮(🗑️)重置对话

2. **API 设置**
   - 点击右上角设置图标(⚙️)
   - 在弹出面板中配置 API 设置
   - 点击关闭按钮保存并返回

3. **思考过程**
   - 点击右下角思考按钮(🧠)查看思考过程
   - 向上滑动查看历史步骤
   - 点击顶部关闭按钮返回对话

### 界面元素说明
1. **消息显示**
   - 用户消息：右侧蓝色气泡
   - 系统回复：左侧深色气泡
   - 时间戳：消息底部显示

2. **思考过程**
   - 步骤编号：顺序显示
   - 类型图标：直观区分步骤类型
   - 详细描述：展示具体思考内容
   - 执行结果：显示操作结果

3. **API 设置面板**
   - 开关控制：一键开启/关闭
   - 文档输入：支持多行文本
   - 状态提示：显示警告和提示信息

### 移动端使用建议
1. **操作建议**
   - 使用现代移动浏览器访问
   - 保持良好的网络连接
   - 注意设备电量消耗

2. **性能优化**
   - 长时间对话建议定期清空
   - 避免输入过长的消息
   - 合理使用 API 调用功能

## 赞助
1. 如果您觉得对您有用的话请给个star或者打赏一下，您的激励会使我更加有动力！！！
![img.png](docs/img.png)

## 新增功能

### API 调用结果等待机制

系统现在支持等待 API 调用结果后再生成完整回答。主要功能包括：

1. API 结果缓存：
   - 系统会临时缓存 API 调用的结果
   - 支持异步等待结果就绪
   - 默认超时时间为 10 秒

2. 使用方式：
   ```python
   # 设置 API 调用结果
   await memory_manager.set_api_result(memory_id, api_result)
   
   # 获取完整内容（包含 API 结果）
   content = await memory_manager.get_complete_content(
       memory_id="memory_id",
       content="原始内容",
       metadata={"api_enabled": True}
   )
   ```

3. 注意事项：
   - API 调用超时后会返回原始内容
   - 可以通过 timeout 参数调整等待时间
   - 建议在高并发场景下适当调整超时时间

## 最新更新

### 记忆系统优化
1. 记忆分类显示
   - 基础记忆显示为"记忆详情"
   - 快照分为"记忆快照"和"元快照"两种类型
   - 支持查看记忆的元数据、摘要和关键点

2. 界面优化
   - 记忆列表显示优化：
     - 显示记忆摘要
     - 显示关键点数量
     - 显示标签信息
     - 显示API调用结果标记
   - 快照列表显示优化：
     - 清晰区分记忆快照和元快照
     - 显示快照摘要
     - 显示关键点数量
   - 移动端适配：
     - 优化按钮显示
     - 支持思考面板的展开/收起
     - 自适应布局

3. 性能优化
   - 虚拟滚动优化
   - 消息懒加载
   - 状态管理优化
   - 移动端性能提升

### API调用功能
- 支持等待API调用结果
- 优化API调用结果的展示
- 改进API调用的响应时间

### 使用说明
1. 记忆管理
   - 在记忆列表中查看基础记忆
   - 在快照列表中查看记忆快照和元快照
   - 点击记忆/快照查看详细信息

2. API调用
   - 使用右上角的API设置按钮配置
   - 可以启用/禁用API调用功能
   - 支持自定义API文档

3. 移动端使用
   - 使用图标按钮操作
   - 点击思考图标展开/收起思考面板
   - 适配小屏幕显示

### 注意事项
1. 记忆系统
   - 记忆详情包含完整的对话内容
   - 记忆快照包含关键信息提取
   - 元快照用于更高层次的总结

2. API调用
   - 启用API调用可能增加响应时间
   - 建议根据需要开启/关闭API功能
   - 确保API文档格式正确

3. 性能建议
   - 定期清理历史记录
   - 合理使用API功能
   - 注意移动端流量消耗